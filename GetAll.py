#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced GetAll.py with CSV-ONLY Based 24-Hour Freshness Policy (v3.1.0)
ENHANCED: Complete 16 Data Types including Quarterly Financial Ratio Analysis
FIXES: Uses ONLY CSV records for freshness, not file timestamps
Correct logic: Use last_update_time from CSV to determine if stock needs reprocessing
"""

import sys
import csv
import subprocess
import os
import time
import pandas as pd
import signal
from datetime import datetime, timedelta
import psutil
import shutil

# Try to set UTF-8 encoding for Windows console
try:
    if sys.platform.startswith('win'):
        import locale
        os.system('chcp 65001 > nul 2>&1')
except:
    pass

# Enhanced data type descriptions for complete 16 data types (v3.1.0)
DATA_TYPE_DESCRIPTIONS = {
    '1': 'Dividend Policy (è‚¡åˆ©æ”¿ç­–) - Weekly automation (Monday 8 AM UTC)',
    '2': 'Basic Info (åŸºæœ¬è³‡æ–™) - Manual only',
    '3': 'Stock Details (å€‹è‚¡å¸‚æ³) - Manual only',
    '4': 'Business Performance (ç¶“ç‡Ÿç¸¾æ•ˆ) - Weekly automation (Tuesday 8 AM UTC)',
    '5': 'Monthly Revenue (æ¯æœˆç‡Ÿæ”¶) - Daily automation (12 PM UTC)',
    '6': 'Equity Distribution (è‚¡æ¬Šçµæ§‹) - Weekly automation (Wednesday 8 AM UTC)',
    '7': 'Quarterly Performance (æ¯å­£ç¶“ç‡Ÿç¸¾æ•ˆ) - Weekly automation (Thursday 8 AM UTC)',
    '8': 'EPS x PER Weekly (æ¯é€±EPSæœ¬ç›Šæ¯”) - Weekly automation (Friday 8 AM UTC)',
    '9': 'Quarterly Analysis (å„å­£è©³ç´°çµ±è¨ˆè³‡æ–™) - Weekly automation (Saturday 8 AM UTC)',
    '10': 'Equity Class Weekly (è‚¡æ±æŒè‚¡åˆ†é¡é€±) - Weekly automation (Sunday 8 AM UTC)',
    '11': 'Weekly Trading Data (é€±äº¤æ˜“è³‡æ–™å«ä¸‰å¤§æ³•äºº) - Weekly automation (Monday Evening)',
    '12': 'EPS x PER Monthly (æ¯æœˆEPSæœ¬ç›Šæ¯”) - Monthly automation (1st Tuesday)', # ğŸ†• NEW in v3.0.0
    '13': 'Daily Margin Balance (æ¯æ—¥èè³‡èåˆ¸é¤˜é¡è©³ç´°è³‡æ–™) - Daily automation (Evening)', # ğŸ†• NEW Type 13
    '14': 'Weekly Margin Balance (æ¯å‘¨èè³‡èåˆ¸é¤˜é¡è©³ç´°è³‡æ–™) - Weekly automation (Friday Evening)', # ğŸ†• NEW Type 14
    '15': 'Monthly Margin Balance (æ¯æœˆèè³‡èåˆ¸é¤˜é¡è©³ç´°è³‡æ–™) - Monthly automation (1st Wednesday)',
    '16': 'Quarterly Financial Ratio Analysis (å–®å­£è²¡å‹™æ¯”ç‡è¡¨è©³ç´°è³‡æ–™) - Monthly automation (1st Wednesday 2:10 PM UTC)' # ğŸ†• NEW Type 16
}

# Global variables for graceful termination
current_results_data = {}
current_process_times = {}
current_last_update_times = {}  # NEW: Track actual completion times
current_retry_stats = {}
current_stock_ids = []
current_parameter = ""
current_stock_mapping = {}

def signal_handler(signum, frame):
    """Handle termination signals gracefully - save CSV before exit"""
    print(f"\nè­¦å‘Š æ”¶åˆ°çµ‚æ­¢ä¿¡è™Ÿ ({signum}) - æ­£åœ¨å„²å­˜é€²åº¦...")

    if current_results_data and current_stock_ids:
        try:
            save_csv_results_csv_only(current_parameter, current_stock_ids,
                                     current_results_data, current_process_times,
                                     current_stock_mapping, current_retry_stats,
                                     current_last_update_times)  # NEW: Pass completion times
            processed_count = len(current_results_data)
            success_count = sum(1 for success in current_results_data.values() if success)
            total_attempts = sum(stats.get('attempts', 1) for stats in current_retry_stats.values()) if current_retry_stats else processed_count
            print(f"ç·Šæ€¥å„²å­˜å®Œæˆ: {processed_count} è‚¡ç¥¨å·²è™•ç†ï¼Œ{success_count} æˆåŠŸï¼Œ{total_attempts} ç¸½å˜—è©¦æ¬¡æ•¸")
        except Exception as e:
            print(f"ç·Šæ€¥å„²å­˜å¤±æ•—: {e}")
    
    print("ç¨‹å¼å·²å®‰å…¨çµ‚æ­¢")
    sys.exit(0)

# Register signal handlers
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def aggressive_chrome_cleanup():
    """Enhanced Chrome process and resource cleanup"""
    cleanup_count = 0
    temp_cleanup_count = 0
    
    try:
        print("ğŸ”¥ åŸ·è¡Œå¼·åŒ– Chrome æ¸…ç†...")
        
        # Method 1: Kill Chrome processes using psutil
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if proc.info['name'] and any(name in proc.info['name'].lower() 
                                           for name in ['chrome', 'chromium', 'chromedriver']):
                    proc.terminate()
                    cleanup_count += 1
                    time.sleep(0.1)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # Wait for graceful termination
        time.sleep(2)
        
        # Method 2: Force kill remaining processes
        for proc in psutil.process_iter(['pid', 'name']):
            try:
                if proc.info['name'] and any(name in proc.info['name'].lower() 
                                           for name in ['chrome', 'chromium']):
                    proc.kill()
                    cleanup_count += 1
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # Method 3: Unix pkill as backup
        try:
            os.system('pkill -f chrome > /dev/null 2>&1')
            os.system('pkill -f chromium > /dev/null 2>&1') 
            os.system('pkill -f chromedriver > /dev/null 2>&1')
        except:
            pass
        
        # Clean temporary directories
        temp_patterns = ['chrome', 'chromium', 'goodinfo', 'selenium', 'webdriver']
        temp_dirs = ['/tmp', '/var/tmp', os.path.expanduser('~/.cache')]
        
        for temp_dir in temp_dirs:
            if os.path.exists(temp_dir):
                try:
                    for item in os.listdir(temp_dir):
                        if any(pattern in item.lower() for pattern in temp_patterns):
                            item_path = os.path.join(temp_dir, item)
                            try:
                                if os.path.isdir(item_path):
                                    shutil.rmtree(item_path, ignore_errors=True)
                                else:
                                    os.remove(item_path)
                                temp_cleanup_count += 1
                            except:
                                pass
                except:
                    pass
        
        print(f"   Chrome ç¨‹åºæ¸…ç†: {cleanup_count} å€‹ç¨‹åº")
        print(f"   æš«å­˜æª”æ¡ˆæ¸…ç†: {temp_cleanup_count} å€‹é …ç›®")
        return cleanup_count + temp_cleanup_count
        
    except Exception as e:
        print(f"æ¸…ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 0

def parse_csv_datetime(date_string):
    """FIXED: Parse CSV datetime strings safely"""
    if not date_string or date_string in ['NOT_PROCESSED', 'NEVER', '', 'nan']:
        return None
    
    try:
        # Handle the format from CSV: '2025-09-03 12:08:54'
        return datetime.strptime(date_string.strip(), '%Y-%m-%d %H:%M:%S')
    except ValueError:
        try:
            # Fallback for date-only format
            return datetime.strptime(date_string.strip(), '%Y-%m-%d')
        except ValueError:
            print(f"   âš ï¸ ç„¡æ³•è§£ææ™‚é–“: {date_string}")
            return None

def run_get_good_info_with_retry(stock_id, parameter, debug_mode=False, max_retries=3):
    """Enhanced retry mechanism with Type 12 considerations"""
    
    # Enhanced timeout configuration including Type 12
    timeout_config = {
        '1': 90,   '2': 60,   '3': 60,   '4': 75,   '5': 90,
        '6': 90,   '7': 90,   '8': 90,   '9': 75,   '10': 90,
        '11': 120, '12': 90, '13': 90, '14': 90, '15': 90  # ğŸ†• Types 13-15 timeouts set to 90s
    }
    
    base_timeout = timeout_config.get(str(parameter), 75)
    backoff_delays = [0, 10, 30, 60]
    
    start_time = time.time()
    last_error = ""
    
    for attempt in range(1, max_retries + 2):
        try:
            # Resource cleanup before retry attempts
            if attempt > 1:
                print(f"   ç¬¬ {attempt} æ¬¡å˜—è©¦ - åŸ·è¡Œè³‡æºæ¸…ç†...")
                cleanup_count = aggressive_chrome_cleanup()
                
                # Progressive backoff delay
                delay = backoff_delays[min(attempt - 1, len(backoff_delays) - 1)]
                if delay > 0:
                    print(f"   ç­‰å¾… {delay} ç§’å†·å»æ™‚é–“...")
                    time.sleep(delay)
            
            # Enhanced timeout for Types 11 and 12
            current_timeout = base_timeout + (attempt - 1) * 30
            if str(parameter) in ['11', '12', '13', '14', '15', '16'] and attempt > 1:
                current_timeout += 30  # Additional time for complex data types
            
            print(f"   å˜—è©¦ {attempt}/4 (è¶…æ™‚: {current_timeout}s)")
            if str(parameter) == '11':
                print(f"   ğŸ”µ Type 11: é€±äº¤æ˜“è³‡æ–™å«ä¸‰å¤§æ³•äººæ•¸æ“šè™•ç†ä¸­...")
            elif str(parameter) == '12':
                print(f"   ğŸ†• Type 12: æ¯æœˆEPSæœ¬ç›Šæ¯”é•·æœŸæ•¸æ“šè™•ç†ä¸­...")
            elif str(parameter) == '13':
                print(f"   ğŸ†• Type 13: æ¯æ—¥èè³‡èåˆ¸é¤˜é¡æ•¸æ“šè™•ç†ä¸­...")
            elif str(parameter) == '14':
                print(f"   ğŸ†• Type 14: æ¯å‘¨èè³‡èåˆ¸é¤˜é¡æ•¸æ“šè™•ç†ä¸­...")
            elif str(parameter) == '15':
                print(f"   ğŸ†• Type 15: æ¯æœˆèè³‡èåˆ¸é¤˜é¡æ•¸æ“šè™•ç†ä¸­...")
            elif str(parameter) == '16':
                print(f"   ğŸ†• Type 16: å–®å­£è²¡å‹™æ¯”ç‡è¡¨æ•¸æ“šè™•ç†ä¸­...")
            
            # Prepare command
            cmd = ['python', 'GetGoodInfo.py', str(stock_id), str(parameter)]
            
            # Set environment
            env = os.environ.copy()
            env['PYTHONIOENCODING'] = 'utf-8'
            
            # Execute with timeout
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=current_timeout,
                env=env,
                encoding='utf-8',
                errors='replace'
            )
            
            # Check success based on return code only (CSV-only approach)
            if result.returncode == 0:
                duration = time.time() - start_time
                success_msg = f"âœ… {stock_id} ç¬¬ {attempt} æ¬¡å˜—è©¦æˆåŠŸ"
                if attempt > 1:
                    success_msg += f" (å‰ {attempt-1} æ¬¡å¤±æ•—å¾Œé‡è©¦æˆåŠŸ)"
                if str(parameter) == '11':
                    success_msg += f" [Type 11 æ©Ÿæ§‹è³‡æ–™å®Œæˆ]"
                elif str(parameter) == '12':
                    success_msg += f" [Type 12 æœˆåº¦P/Eå®Œæˆ]"
                elif str(parameter) == '13':
                    success_msg += f" [Type 13 èè³‡èåˆ¸å®Œæˆ]"
                elif str(parameter) == '14':
                    success_msg += f" [Type 14 æ¯å‘¨èè³‡èåˆ¸å®Œæˆ]"
            elif str(parameter) == '15':
                success_msg += f" [Type 15 æ¯æœˆèè³‡èåˆ¸å®Œæˆ]"
            elif str(parameter) == '16':
                success_msg += f" [Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨å®Œæˆ]"
                print(success_msg)
                
                # Show output for retries or debug mode
                if (debug_mode or attempt > 1) and result.stdout:
                    output_lines = result.stdout.strip().split('\n')
                    if len(output_lines) <= 3:
                        print(f"   è¼¸å‡º: {result.stdout.strip()}")
                    else:
                        print(f"   è¼¸å‡º: {output_lines[0]}")
                        print(f"        ... ({len(output_lines)} è¡Œè¼¸å‡º)")
                
                return True, attempt, "", duration
            
            # Handle failure
            else:
                error_msg = f"é€€å‡ºç¢¼ {result.returncode}"
                if result.stderr and result.stderr.strip():
                    stderr_lines = result.stderr.strip().split('\n')
                    error_msg += f" - {stderr_lines[0]}"
                    if len(stderr_lines) > 1:
                        error_msg += f" (+{len(stderr_lines)-1} è¡ŒéŒ¯èª¤)"
                
                last_error = error_msg
                print(f"   âŒ ç¬¬ {attempt} æ¬¡å˜—è©¦å¤±æ•—: {error_msg}")
                
                # Don't retry certain error types
                if result.returncode in [2, 127]:
                    print(f"   ğŸ›‘ è‡´å‘½éŒ¯èª¤ï¼Œåœæ­¢é‡è©¦")
                    break
                
                continue
                
        except subprocess.TimeoutExpired:
            timeout_msg = f"è¶…æ™‚ ({current_timeout}ç§’)"
            if str(parameter) == '11':
                timeout_msg += " [Type 11 æ©Ÿæ§‹æ•¸æ“šè¤‡é›œåº¦]"
            elif str(parameter) == '12':
                timeout_msg += " [Type 12 æœˆåº¦æ•¸æ“šè¤‡é›œåº¦]"
            elif str(parameter) == '13':
                timeout_msg += " [Type 13 æ¯æ—¥æ•¸æ“šè¤‡é›œåº¦]"
            elif str(parameter) == '14':
                timeout_msg += " [Type 14 æ¯å‘¨æ•¸æ“šè¤‡é›œåº¦]"
            elif str(parameter) == '15':
                timeout_msg += " [Type 15 æ¯æœˆæ•¸æ“šè¤‡é›œåº¦]"
            elif str(parameter) == '16':
                timeout_msg += " [Type 16 å–®å­£æ•¸æ“šè¤‡é›œåº¦]"
            last_error = timeout_msg
            print(f"   â° ç¬¬ {attempt} æ¬¡å˜—è©¦è¶…æ™‚: {timeout_msg}")
            
            # Force cleanup after timeout
            if attempt < max_retries + 1:
                print(f"   ğŸ§¹ è¶…æ™‚å¾ŒåŸ·è¡Œç·Šæ€¥æ¸…ç†...")
                aggressive_chrome_cleanup()
            
            continue
            
        except KeyboardInterrupt:
            print(f"   âš ï¸ ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
            raise
            
        except Exception as e:
            error_msg = f"åŸ·è¡Œç•°å¸¸: {str(e)}"
            last_error = error_msg
            print(f"   ğŸ’¥ ç¬¬ {attempt} æ¬¡å˜—è©¦ç•°å¸¸: {error_msg}")
            continue
    
    # All attempts failed
    duration = time.time() - start_time
    total_attempts = max_retries + 1
    failure_msg = f"   âŒ æœ€çµ‚å¤±æ•—: ç¶“é 4 æ¬¡å˜—è©¦ä»å¤±æ•—"
    if str(parameter) == '11':
        failure_msg += f" [Type 11 æ©Ÿæ§‹æ•¸æ“šè™•ç†å¤±æ•—]"
    elif str(parameter) == '12':
        failure_msg += f" [Type 12 æœˆåº¦P/Eè™•ç†å¤±æ•—]"
    elif str(parameter) == '13':
        failure_msg += f" [Type 13 èè³‡èåˆ¸è™•ç†å¤±æ•—]"
    elif str(parameter) == '14':
        failure_msg += f" [Type 14 æ¯å‘¨èè³‡èåˆ¸è™•ç†å¤±æ•—]"
    elif str(parameter) == '15':
        failure_msg += f" [Type 15 æ¯æœˆèè³‡èåˆ¸è™•ç†å¤±æ•—]"
    elif str(parameter) == '16':
        failure_msg += f" [Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨è™•ç†å¤±æ•—]"
    print(failure_msg)
    print(f"   ğŸ” æœ€å¾ŒéŒ¯èª¤: {last_error}")
    return False, total_attempts, last_error, duration

def determine_stocks_to_process_csv_only(parameter, all_stock_ids, stock_mapping, debug_mode=False):
    """Enhanced CSV-ONLY: Determine which stocks need processing including Type 12 support"""
    
    # Enhanced folder mapping for complete 16 data types (v3.1.0)
    folder_mapping = {
        '1': 'DividendDetail', '2': 'BasicInfo', '3': 'StockDetail',
        '4': 'StockBzPerformance', '5': 'ShowSaleMonChart', '6': 'EquityDistribution',
        '7': 'StockBzBzPerformance1', '8': 'ShowK_ChartFlow', '9': 'StockHisAnaQuar',
        '10': 'EquityDistributionClassHis', '11': 'WeeklyTradingData', '12': 'ShowMonthlyK_ChartFlow',
        '13': 'ShowMarginChart', '14': 'ShowMarginChartWeek', '15': 'ShowMarginChartMonth',
        '16': 'StockFinDetail'  # ğŸ†• NEW Type 16
    }
    folder = folder_mapping.get(parameter, f'DataType{parameter}')
    
    # Load existing CSV data
    existing_data = {}
    csv_filepath = os.path.join(folder, "download_results.csv")
    
    if os.path.exists(csv_filepath):
        try:
            with open(csv_filepath, 'r', newline='', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    filename = row.get('filename', '')
                    if filename:
                        existing_data[filename] = {
                            'last_update_time': row.get('last_update_time', 'NEVER'),
                            'success': row.get('success', 'false'),
                            'process_time': row.get('process_time', 'NOT_PROCESSED'),
                            'retry_count': int(row.get('retry_count', 0))
                        }
        except Exception as e:
            print(f"ç„¡æ³•è®€å–ç¾æœ‰CSVæ•¸æ“š: {e}")
    
    # Enhanced CSV-ONLY analysis with Type 12 considerations
    now = datetime.now()
    failed_stocks = []
    not_processed_stocks = []
    fresh_success = []
    expired_success = []
    
    print(f"ğŸ“‹ CSV-ONLY åˆ†æ {len(all_stock_ids)} æ”¯è‚¡ç¥¨çš„è¨˜éŒ„ç‹€æ…‹ (24å°æ™‚æ–°é®®åº¦æ”¿ç­–)...")
    if str(parameter) == '11':
        print(f"   ğŸ”µ Type 11: é€±äº¤æ˜“è³‡æ–™å«ä¸‰å¤§æ³•äºº - æ©Ÿæ§‹æ•¸æ“šè¤‡é›œåº¦è™•ç†")
    elif str(parameter) == '12':
        print(f"   ğŸ†• Type 12: æ¯æœˆEPSæœ¬ç›Šæ¯” - 20å¹´æœˆåº¦P/Eæ•¸æ“šè¤‡é›œåº¦è™•ç†")
    elif str(parameter) == '13':
        print(f"   ğŸ†• Type 13: æ¯æ—¥èè³‡èåˆ¸é¤˜é¡ - æ¯æ—¥æ•¸æ“šè¤‡é›œåº¦è™•ç†")
    elif str(parameter) == '14':
        print(f"   ğŸ†• Type 14: æ¯å‘¨èè³‡èåˆ¸é¤˜é¡ - æ¯å‘¨æ•¸æ“šè¤‡é›œåº¦è™•ç†")
    elif str(parameter) == '15':
        print(f"   ğŸ†• Type 15: æ¯æœˆèè³‡èåˆ¸é¤˜é¡ - æ¯æœˆæ•¸æ“šè¤‡é›œåº¦è™•ç†")
    elif str(parameter) == '16':
        print(f"   ğŸ†• Type 16: å–®å­£è²¡å‹™æ¯”ç‡è¡¨ - å–®å­£æ¯”ç‡åˆ†ææ•¸æ“šè™•ç†")
    if debug_mode:
        print(f"   ç•¶å‰æ™‚é–“: {now}")
    
    for stock_id in all_stock_ids:
        company_name = stock_mapping.get(stock_id, f'è‚¡ç¥¨{stock_id}')
        
        # Generate expected filename with Type 12 support
        if parameter == '7':
            filename = f"StockBzPerformance1_{stock_id}_{company_name}_quarter.xls"
        else:
            filename = f"{folder}_{stock_id}_{company_name}.xls"
        
        # Check CSV record
        if filename in existing_data:
            record = existing_data[filename]
            success = record['success'].lower() == 'true'
            last_update_time_str = record['last_update_time']
            
            if last_update_time_str in ['NOT_PROCESSED', 'NEVER', '']:
                not_processed_stocks.append(stock_id)
                if debug_mode:
                    print(f"   {stock_id}: CSVé¡¯ç¤ºæœªè™•ç† -> éœ€è™•ç†")
                continue
            
            # Parse the last_update_time from CSV
            last_update_time = parse_csv_datetime(last_update_time_str)
            
            if last_update_time is None:
                not_processed_stocks.append(stock_id)
                if debug_mode:
                    print(f"   {stock_id}: ç„¡æ³•è§£ææ™‚é–“ '{last_update_time_str}' -> éœ€è™•ç†")
                continue
            
            # Calculate age based on CSV timestamp
            time_diff = now - last_update_time
            hours_ago = time_diff.total_seconds() / 3600
            
            if debug_mode:
                debug_msg = f"   {stock_id}: CSVæ™‚é–“ {last_update_time}, {hours_ago:.1f}hå‰, æˆåŠŸ={success}"
                if str(parameter) == '11':
                    debug_msg += " [Type 11]"
                elif str(parameter) == '12':
                    debug_msg += " [Type 12]"
                elif str(parameter) == '13':
                    debug_msg += " [Type 13]"
                elif str(parameter) == '14':
                    debug_msg += " [Type 14]"
                elif str(parameter) == '15':
                    debug_msg += " [Type 15]"
                print(debug_msg)
            
            if not success:
                failed_stocks.append(stock_id)
                if debug_mode:
                    print(f"   {stock_id}: CSVé¡¯ç¤ºå¤±æ•— -> éœ€é‡è©¦")
            elif hours_ago <= 24:
                fresh_success.append(stock_id)
                if debug_mode:
                    print(f"   {stock_id}: {hours_ago:.1f}h æ–°é®® -> è·³é")
            else:
                expired_success.append(stock_id)
                if debug_mode:
                    print(f"   {stock_id}: {hours_ago:.1f}h éæœŸ -> éœ€æ›´æ–°")
        else:
            not_processed_stocks.append(stock_id)
            if debug_mode:
                print(f"   {stock_id}: CSVä¸­ç„¡è¨˜éŒ„ -> éœ€è™•ç†")
    
    priority_stocks = failed_stocks + not_processed_stocks + expired_success
    
    print(f"è™•ç†ç‹€æ…‹åˆ†æ ({folder}) - CSV-ONLY 24å°æ™‚æ–°é®®åº¦æ”¿ç­–:")
    print(f"   å¤±æ•—è‚¡ç¥¨: {len(failed_stocks)} (CSVæ¨™è¨˜å¤±æ•—)")
    print(f"   æœªè™•ç†è‚¡ç¥¨: {len(not_processed_stocks)} (CSVç„¡è¨˜éŒ„æˆ–æœªè™•ç†)")
    print(f"   æ–°é®®æˆåŠŸ (â‰¤24å°æ™‚): {len(fresh_success)} (è·³é)")
    print(f"   éæœŸæˆåŠŸ (>24å°æ™‚): {len(expired_success)} (éœ€æ›´æ–°)")
    
    # Enhanced debug for Types 11-16
    if debug_mode and expired_success and str(parameter) in ['11', '12', '13', '14', '15']:
        type_label = f"Type {parameter}"
        if parameter == '11': type_label = 'ğŸ”µ Type 11'
        elif parameter in ['12', '13', '14', '15']: type_label = f'ğŸ†• Type {parameter}'
        
        print(f"   {type_label} éæœŸè‚¡ç¥¨ç¯„ä¾‹:")
        for stock_id in expired_success[:5]:
            company_name = stock_mapping.get(stock_id, f'è‚¡ç¥¨{stock_id}')
            filename = f"{folder}_{stock_id}_{company_name}.xls"
            
            if filename in existing_data:
                last_update_str = existing_data[filename]['last_update_time']
                last_update_time = parse_csv_datetime(last_update_str)
                if last_update_time:
                    hours_ago = (now - last_update_time).total_seconds() / 3600
                    data_type_label = "æ©Ÿæ§‹æ•¸æ“š" if parameter == '11' else ("æœˆåº¦P/E" if parameter == '12' else ("æ¯æ—¥èè³‡" if parameter == '13' else ("æ¯å‘¨èè³‡" if parameter == '14' else "æ¯æœˆèè³‡")))
                    print(f"     {stock_id}: CSVæ™‚é–“ {last_update_str} ({hours_ago:.1f}hå‰) [{data_type_label}]")
    
    if priority_stocks:
        reprocess_reasons = []
        if failed_stocks:
            reprocess_reasons.append(f"{len(failed_stocks)}å€‹å¤±æ•—")
        if not_processed_stocks:
            reprocess_reasons.append(f"{len(not_processed_stocks)}å€‹æœªè™•ç†")
        if expired_success:
            reprocess_reasons.append(f"{len(expired_success)}å€‹éæœŸæˆåŠŸ")
        
        reason_str = "ã€".join(reprocess_reasons)
        strategy_msg = f"éœ€è¦è™•ç†ç­–ç•¥: è™•ç† {len(priority_stocks)} å€‹è‚¡ç¥¨ ({reason_str})"
        if str(parameter) == '11':
            strategy_msg += f" [Type 11 æ©Ÿæ§‹æ•¸æ“š]"
        elif str(parameter) == '12':
            strategy_msg += f" [Type 12 æœˆåº¦P/E]"
        elif str(parameter) == '13':
            strategy_msg += f" [Type 13 èè³‡èåˆ¸]"
        elif str(parameter) == '14':
            strategy_msg += f" [Type 14 æ¯å‘¨èè³‡èåˆ¸]"
        elif str(parameter) == '15':
            strategy_msg += f" [Type 15 æ¯æœˆèè³‡èåˆ¸]"
        print(strategy_msg)
        return priority_stocks, "REPROCESS_NEEDED"
    elif fresh_success:
        print(f"ç„¡éœ€è™•ç†: æ‰€æœ‰ {len(fresh_success)} å€‹è‚¡ç¥¨åœ¨24å°æ™‚å…§å·²æˆåŠŸè™•ç†")
        return [], "UP_TO_DATE"
    else:
        scan_msg = f"åˆå§‹æƒæ: åŸ·è¡Œé¦–æ¬¡å®Œæ•´æƒæ"
        if str(parameter) == '11':
            scan_msg += f" [Type 11 æ©Ÿæ§‹æ•¸æ“šåˆå§‹åŒ–]"
        elif str(parameter) == '12':
            scan_msg += f" [Type 12 æœˆåº¦P/Eåˆå§‹åŒ–]"
        elif str(parameter) == '13':
            scan_msg += f" [Type 13 èè³‡èåˆ¸åˆå§‹åŒ–]"
        elif str(parameter) == '14':
            scan_msg += f" [Type 14 æ¯å‘¨èè³‡èåˆ¸åˆå§‹åŒ–]"
        elif str(parameter) == '15':
            scan_msg += f" [Type 15 æ¯æœˆèè³‡èåˆ¸åˆå§‹åŒ–]"
        elif str(parameter) == '16':
            scan_msg += f" [Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨åˆå§‹åŒ–]"
        print(scan_msg)
        return all_stock_ids, "INITIAL_SCAN"

def save_csv_results_csv_only(parameter, stock_ids, results_data, process_times, stock_mapping, retry_stats=None, last_update_times=None):
    """Enhanced CSV-ONLY: Save CSV results with per-stock completion timestamps"""
    
    # Enhanced folder mapping for complete 16 data types (v3.1.0)
    folder_mapping = {
        '1': 'DividendDetail', '2': 'BasicInfo', '3': 'StockDetail',
        '4': 'StockBzPerformance', '5': 'ShowSaleMonChart', '6': 'EquityDistribution',
        '7': 'StockBzPerformance1', '8': 'ShowK_ChartFlow', '9': 'StockHisAnaQuar',
        '10': 'EquityDistributionClassHis', '11': 'WeeklyTradingData', '12': 'ShowMonthlyK_ChartFlow',
        '13': 'ShowMarginChart', '14': 'ShowMarginChartWeek', '15': 'ShowMarginChartMonth',
        '16': 'StockFinDetail'  # ğŸ†• NEW Type 16
    }
    folder = folder_mapping.get(parameter, f'DataType{parameter}')
    
    if not os.path.exists(folder):
        os.makedirs(folder)
        create_msg = f"å»ºç«‹è³‡æ–™å¤¾: {folder}"
        if str(parameter) == '11':
            create_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“šè³‡æ–™å¤¾]"
        elif str(parameter) == '12':
            create_msg += f" [ğŸ†• Type 12 æœˆåº¦P/Eè³‡æ–™å¤¾]"
        elif str(parameter) == '13':
            create_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸è³‡æ–™å¤¾]"
        elif str(parameter) == '14':
            create_msg += f" [ğŸ†• Type 14 æ¯å‘¨èè³‡èåˆ¸è³‡æ–™å¤¾]"
        elif str(parameter) == '15':
            create_msg += f" [ğŸ†• Type 15 æ¯æœˆèè³‡èåˆ¸è³‡æ–™å¤¾]"
        elif str(parameter) == '16':
            create_msg += f" [ğŸ†• Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨è³‡æ–™å¤¾]"
        print(create_msg)
    
    csv_filepath = os.path.join(folder, "download_results.csv")
    
    # Load existing data for stocks not processed in current run
    existing_data = {}
    if os.path.exists(csv_filepath):
        try:
            with open(csv_filepath, 'r', newline='', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    filename = row.get('filename', '')
                    if filename:
                        existing_data[filename] = {
                            'last_update_time': row.get('last_update_time', 'NEVER'),
                            'success': row.get('success', 'false'),
                            'process_time': row.get('process_time', 'NOT_PROCESSED'),
                            'retry_count': int(row.get('retry_count', 0))
                        }
        except Exception as e:
            print(f"è­¦å‘Š: ç„¡æ³•è¼‰å…¥ç¾æœ‰ CSV: {e}")
    
    try:
        with open(csv_filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['filename', 'last_update_time', 'success', 'process_time', 'retry_count'])
            
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            for stock_id in stock_ids:
                company_name = stock_mapping.get(stock_id, f'è‚¡ç¥¨{stock_id}')
                
                # Enhanced filename generation with Type 12 support
                if parameter == '7':
                    filename = f"StockBzPerformance1_{stock_id}_{company_name}_quarter.xls"
                else:
                    filename = f"{folder}_{stock_id}_{company_name}.xls"
                
                if stock_id in results_data:
                    # Current processing data
                    success = str(results_data[stock_id]).lower()
                    process_time = process_times.get(stock_id, 'NOT_PROCESSED')
                    total_attempts = retry_stats.get(stock_id, {}).get('attempts', 1) if retry_stats else 1
                    retry_count = max(0, total_attempts - 1)

                    # NEW: Use per-stock completion time for accurate timestamps
                    if success == 'true':
                        # Use actual download completion time if available, fallback to current_time
                        last_update = last_update_times.get(stock_id, current_time) if last_update_times else current_time
                    else:
                        # Failed - preserve existing timestamp if it exists
                        if filename in existing_data:
                            last_update = existing_data[filename]['last_update_time']
                        else:
                            last_update = 'NEVER'
                else:
                    # Existing data (not processed in current run)
                    if filename in existing_data:
                        existing_record = existing_data[filename]
                        last_update = existing_record['last_update_time']
                        success = existing_record['success']
                        process_time = existing_record['process_time']
                        retry_count = existing_record.get('retry_count', 0)
                    else:
                        # New stock not yet processed
                        last_update = 'NEVER'
                        success = 'false'
                        process_time = 'NOT_PROCESSED'
                        retry_count = 0
                
                writer.writerow([filename, last_update, success, process_time, retry_count])
        
        save_msg = f"CSV-ONLY CSVçµæœå·²å„²å­˜: {csv_filepath}"
        if str(parameter) == '11':
            save_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“šè¨˜éŒ„]"
        elif str(parameter) == '12':
            save_msg += f" [ğŸ†• Type 12 æœˆåº¦P/Eè¨˜éŒ„]"
        elif str(parameter) == '13':
            save_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸è¨˜éŒ„]"
        elif str(parameter) == '14':
            save_msg += f" [ğŸ†• Type 14 æ¯å‘¨èè³‡èåˆ¸è¨˜éŒ„]"
        elif str(parameter) == '15':
            save_msg += f" [ğŸ†• Type 15 æ¯æœˆèè³‡èåˆ¸è¨˜éŒ„]"
        elif str(parameter) == '16':
            save_msg += f" [ğŸ†• Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨è¨˜éŒ„]"
        print(save_msg)
        
        # Enhanced summary with Types 11-16 support
        if results_data:
            total_stocks = len(stock_ids)
            processed_count = len(results_data)
            success_count = sum(1 for success in results_data.values() if success)
            success_rate = (success_count / processed_count * 100) if processed_count > 0 else 0
            
            summary_title = f"{folder} æ‘˜è¦ (CSV-ONLYç‰ˆæœ¬"
            if str(parameter) == '11':
                summary_title += f" - Type 11 æ©Ÿæ§‹æ•¸æ“š"
            elif str(parameter) == '12':
                summary_title += f" - Type 12 æœˆåº¦P/E"
            elif str(parameter) == '13':
                summary_title += f" - Type 13 èè³‡èåˆ¸"
            elif str(parameter) == '14':
                summary_title += f" - Type 14 æ¯å‘¨èè³‡èåˆ¸"
            elif str(parameter) == '15':
                summary_title += f" - Type 15 æ¯æœˆèè³‡èåˆ¸"
            elif str(parameter) == '16':
                summary_title += f" - Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨"
            summary_title += "):"
            print(summary_title)
            
            print(f"   CSV ç¸½è‚¡ç¥¨æ•¸: {total_stocks}")
            print(f"   æœ¬æ¬¡è™•ç†è‚¡ç¥¨æ•¸: {processed_count}")
            print(f"   æœ¬æ¬¡æˆåŠŸæ•¸: {success_count}")
            print(f"   æœ¬æ¬¡æˆåŠŸç‡: {success_rate:.1f}%")
            
            if retry_stats:
                total_attempts = sum(stats.get('attempts', 1) for stats in retry_stats.values())
                total_retries = sum(max(0, stats.get('attempts', 1) - 1) for stats in retry_stats.values())
                print(f"   ç¸½å˜—è©¦æ¬¡æ•¸: {total_attempts}")
                print(f"   ç¸½é‡è©¦æ¬¡æ•¸: {total_retries}")
                
                # Types 11-16 specific retry analysis
                if str(parameter) in ['11', '12', '13', '14', '15', '16'] and total_retries > 0:
                    avg_retries = total_retries / processed_count if processed_count > 0 else 0
                    if parameter == '11':
                        data_type_label = "æ©Ÿæ§‹æ•¸æ“šè¤‡é›œåº¦"
                    elif parameter == '12':
                        data_type_label = "æœˆåº¦P/Eè¤‡é›œåº¦"
                    elif parameter == '16':
                        data_type_label = "å–®å­£æ¯”ç‡è¤‡é›œåº¦"
                    else:
                        data_type_label = "èè³‡èåˆ¸è¤‡é›œåº¦"
                    print(f"   {'ğŸ”µ' if parameter == '11' else 'ğŸ†•'} Type {parameter} å¹³å‡é‡è©¦: {avg_retries:.1f} ({data_type_label})")
            
            print(f"   CSV ä½ç½®: {csv_filepath}")
        
    except Exception as e:
        print(f"å„²å­˜ CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# Original helper functions (enhanced for Type 12)
def read_stock_ids(csv_file):
    """Read stock IDs from CSV file with enhanced encoding support"""
    stock_ids = []
    encodings = ['utf-8', 'big5', 'utf-8-sig']
    
    for encoding in encodings:
        try:
            with open(csv_file, 'r', encoding=encoding) as f:
                first_line = f.readline()
                f.seek(0)
                reader = csv.reader(f)
                
                # Skip header if detected
                first_row = next(reader)
                if any('è‚¡' in str(cell) or 'StockID' in str(cell) or 'ID' in str(cell) 
                      or 'ä»£è™Ÿ' in str(cell) or 'Code' in str(cell) for cell in first_row):
                    print(f"åµæ¸¬åˆ°æ¨™é¡Œè¡Œ: {first_row}")
                else:
                    stock_id = first_row[0].strip() if first_row and len(first_row) > 0 else ""
                    if stock_id and stock_id.isdigit() and 4 <= len(stock_id) <= 6:
                        stock_ids.append(stock_id)
                
                # Read remaining rows
                for row in reader:
                    if row and len(row) > 0 and row[0].strip():
                        stock_id = row[0].strip()
                        if stock_id.isdigit() and 4 <= len(stock_id) <= 6:
                            stock_ids.append(stock_id)
            
            print(f"æˆåŠŸä½¿ç”¨ {encoding} ç·¨ç¢¼è®€å–æª”æ¡ˆ")
            break
            
        except UnicodeDecodeError:
            continue
        except Exception as e:
            print(f"ä½¿ç”¨ {encoding} ç·¨ç¢¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
    
    return stock_ids

def load_stock_mapping(csv_file):
    """Load stock ID to company name mapping from CSV file"""
    stock_mapping = {}
    try:
        encodings = ['utf-8', 'big5', 'utf-8-sig']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(csv_file, encoding=encoding)
                
                stock_id_col = None
                company_name_col = None
                
                for col in df.columns:
                    if any(keyword in str(col) for keyword in ['ä»£è™Ÿ', 'ID', 'Code', 'Stock']):
                        stock_id_col = col
                    elif any(keyword in str(col) for keyword in ['åç¨±', 'Name', 'Company', 'å…¬å¸']):
                        company_name_col = col
                
                if stock_id_col is not None and company_name_col is not None:
                    for _, row in df.iterrows():
                        stock_id = str(row[stock_id_col]).strip()
                        company_name = str(row[company_name_col]).strip()
                        if stock_id and company_name and stock_id != 'nan' and company_name != 'nan':
                            stock_mapping[stock_id] = company_name
                    
                    print(f"è¼‰å…¥ {len(stock_mapping)} å€‹è‚¡ç¥¨åç¨±å°æ‡‰")
                    break
                
            except UnicodeDecodeError:
                continue
            except Exception:
                continue
        
        if not stock_mapping:
            print("ç„¡æ³•è¼‰å…¥è‚¡ç¥¨åç¨±å°æ‡‰ï¼Œå°‡ä½¿ç”¨é è¨­åç¨±")
        
    except Exception as e:
        print(f"è¼‰å…¥è‚¡ç¥¨åç¨±å°æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return stock_mapping

def show_enhanced_usage():
    """Show enhanced usage information for v3.1.0 with complete 16 data types"""
    print("=" * 70)
    print("Enhanced Batch Stock Data Downloader (v3.1.0)")
    print("Complete 16 Data Types with CSV-ONLY 24-Hour Freshness Policy")
    print("ENHANCED: EPS x PER Monthly & Multi-Frequency Margin Balance for Long-Term Valuation & Sentiment Analysis")
    print("FIXED: Uses ONLY CSV records for freshness, ignores file timestamps")
    print("=" * 70)
    print()
    print("CSV-ONLY FEATURES:")
    print("   âœ… CSV-ONLY Policy: Uses CSV last_update_time for freshness")
    print("   âœ… No File Checks: Ignores file timestamps entirely")
    print("   âœ… Pipeline Compatible: Works in CI/CD where files are always new")
    print("   âœ… Accurate Tracking: CSV is source of truth for processing history")
    print("   ğŸ”µ Type 11 Support: Weekly Trading Data with Institutional Flows")
    print("   ğŸ†• Type 12 Support: EPS x PER Monthly for Long-Term Analysis")
    print("   ğŸ†• Type 13 Support: Daily Margin Balance for Market Sentiment")
    print("   ğŸ†• Type 14 Support: Weekly Margin Balance")
    print("   ğŸ†• Type 15 Support: Monthly Margin Balance")
    print("   ğŸ†• Type 16 Support: Quarterly Financial Ratio Analysis")
    print("   ğŸ”§ Enhanced Debug: Detailed CSV record analysis")
    print()
    print("Data Types (Complete 16 Types - v3.1.0 ENHANCED):")
    for dt, desc in DATA_TYPE_DESCRIPTIONS.items():
        if dt == '11':
            print(f"   {dt} = {desc} ğŸ”µ")
        elif dt in ['12', '13', '14', '15', '16']:
            print(f"   {dt} = {desc} ğŸ†• NEW!")
        else:
            print(f"   {dt} = {desc}")
    print()
    print("Type 12 Features (NEW!):")
    print("   ğŸ“Š 20-year monthly EPS and P/E ratio data")
    print("   ğŸ“ˆ Conservative P/E multiples (9X-19X) for long-term analysis")
    print("   ğŸ“… Monthly frequency for fundamental analysis")
    print("   ğŸ” Backtesting support with extended historical coverage")
    print("   ğŸ“‹ Complements Type 8 weekly analysis (15X-30X multiples)")
    print("   ğŸ¯ Long-term valuation modeling and portfolio management")
    print()
    print("Type 13/14/15 Features (NEW!):")
    print("   ğŸ“Š Margin Balance & Short Selling data (Daily/Weekly/Monthly)")
    print("   ğŸ“ˆ Margin Usage Rate & Maintenance Rate analysis")
    print("   ğŸ“… Multi-frequency suitable for market sentiment tracking")
    print("   ğŸ” 1-year (Daily), 5-year (Weekly), 20-year (Monthly) history")
    print("   ğŸ“‹ Complements Type 11 weekly trading data")
    print()
    print("Type 16 Features (NEW!):")
    print("   ğŸ“Š Quarterly financial ratio analysis (latest 10 quarters)")
    print("   ğŸ“ˆ Profitability, efficiency, and solvency ratio review")
    print("   ğŸ“… Quarterly granularity for fundamentals tracking")
    print("   ğŸ“‹ Complements quarterly performance and analysis types")
    print()
    print("Options:")
    print("   --test   = Process only first 3 stocks (testing)")
    print("   --debug  = Show detailed CSV record analysis")
    print("   --direct = Simple execution mode (compatibility test)")
    print()
    print("CSV-ONLY Examples (v3.1.0):")
    print("   python GetAll.py 1          # CSV-ONLY: accurate freshness from records")
    print("   python GetAll.py 11         # CSV-ONLY: Type 11 institutional flows ğŸ”µ")
    print("   python GetAll.py 12         # CSV-ONLY: Type 12 monthly P/E analysis ğŸ†•")
    print("   python GetAll.py 13         # CSV-ONLY: Type 13 daily margin balance ğŸ†•")
    print("   python GetAll.py 14         # CSV-ONLY: Type 14 weekly margin balance ğŸ†•")
    print("   python GetAll.py 15         # CSV-ONLY: Type 15 monthly margin balance ğŸ†•")
    print("   python GetAll.py 16         # CSV-ONLY: Type 16 quarterly financial ratio analysis ğŸ†•")
    print("   python GetAll.py 12 --debug # CSV-ONLY: Type 12 with detailed analysis ğŸ†•")  
    print("   python GetAll.py 7 --test   # CSV-ONLY: test mode with CSV analysis")
    print()

def main():
    """Enhanced CSV-ONLY main function with complete 16 data types support (v3.1.0)"""
    global current_results_data, current_process_times, current_last_update_times, current_stock_ids, current_parameter, current_stock_mapping
    
    print("=" * 70)
    print("Enhanced Batch Stock Data Downloader (v3.1.0)")
    print("Complete 16 Data Types with CSV-ONLY 24-Hour Freshness Policy")
    print("ENHANCED: EPS x PER Monthly for Long-Term Valuation Analysis")
    print("FIXED: Uses ONLY CSV records for freshness determination")
    print("Pipeline compatible - ignores file timestamps entirely")
    print("=" * 70)
    
    # Check command line arguments
    if len(sys.argv) < 2:
        show_enhanced_usage()
        print("Error: Please provide DATA_TYPE parameter")
        print("Examples:")
        print("   python GetAll.py 1      # CSV-ONLY dividend data processing")
        print("   python GetAll.py 6      # CSV-ONLY equity distribution")
        print("   python GetAll.py 11     # CSV-ONLY weekly trading data ğŸ”µ")
        print("   python GetAll.py 12     # CSV-ONLY monthly P/E analysis (NEW!) ğŸ†•")
        print("   python GetAll.py 13     # CSV-ONLY daily margin balance (NEW!) ğŸ†•")
        print("   python GetAll.py 14     # CSV-ONLY weekly margin balance (NEW!) ğŸ†•")
        print("   python GetAll.py 15     # CSV-ONLY monthly margin balance (NEW!) ğŸ†•")
        sys.exit(1)
    
    parameter = sys.argv[1]
    test_mode = '--test' in sys.argv
    debug_mode = '--debug' in sys.argv
    direct_mode = '--direct' in sys.argv
    csv_file = "StockID_TWSE_TPEX.csv"
    
    # Enhanced validation for complete 16 data types
    if parameter not in DATA_TYPE_DESCRIPTIONS:
        print(f"Invalid data type: {parameter}")
        print("Valid data types:")
        for dt, desc in DATA_TYPE_DESCRIPTIONS.items():
            if dt == '11':
                print(f" {dt} = {desc} ğŸ”µ")
            elif dt in ['12', '13', '14', '15', '16']:
                print(f" {dt} = {desc} ğŸ†• NEW!")
            else:
                print(f" {dt} = {desc}")
        sys.exit(1)
    
    # Check files
    if not os.path.exists(csv_file):
        print(f"[ERROR] æ‰¾ä¸åˆ°æª”æ¡ˆ: {csv_file}")
        print("è«‹å…ˆåŸ·è¡Œ Getè§€å¯Ÿåå–®.py ä¸‹è¼‰è‚¡ç¥¨æ¸…å–®")
        sys.exit(1)
    
    if not os.path.exists("GetGoodInfo.py"):
        print("[ERROR] æ‰¾ä¸åˆ° GetGoodInfo.py")
        sys.exit(1)
    
    # Read stock IDs and mapping
    print(f"[è®€å–] è®€å–è‚¡ç¥¨æ¸…å–®: {csv_file}")
    stock_ids = read_stock_ids(csv_file)
    
    if not stock_ids:
        print("[ERROR] æœªæ‰¾åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼")
        sys.exit(1)
    
    print(f"[è®€å–] è¼‰å…¥è‚¡ç¥¨åç¨±å°æ‡‰...")
    stock_mapping = load_stock_mapping(csv_file)
    
    # Set global variables for signal handler
    current_stock_ids = stock_ids
    current_parameter = parameter  
    current_stock_mapping = stock_mapping
    global current_retry_stats
    current_retry_stats = {}
    
    print(f"[çµ±è¨ˆ] æ‰¾åˆ° {len(stock_ids)} æ”¯è‚¡ç¥¨")
    print(f"å‰5æ”¯è‚¡ç¥¨: {stock_ids[:5]}")
    
    data_desc = DATA_TYPE_DESCRIPTIONS.get(parameter, f"Data Type {parameter}")
    
    if test_mode:
        stock_ids = stock_ids[:3]
        test_msg = f"[æ¸¬è©¦æ¨¡å¼] åªè™•ç†å‰ {len(stock_ids)} æ”¯è‚¡ç¥¨"
        if parameter == '11':
            test_msg += f" [ğŸ”µ Type 11 æ¸¬è©¦]"
        elif parameter == '12':
            test_msg += f" [ğŸ†• Type 12 æ¸¬è©¦]"
        elif parameter == '13':
            test_msg += f" [ğŸ†• Type 13 æ¸¬è©¦]"
        elif parameter == '14':
            test_msg += f" [ğŸ†• Type 14 æ¸¬è©¦]"
        elif parameter == '15':
            test_msg += f" [ğŸ†• Type 15 æ¸¬è©¦]"
        elif parameter == '16':
            test_msg += f" [ğŸ†• Type 16 æ¸¬è©¦]"
        print(test_msg)
    
    if debug_mode:
        debug_msg = "[é™¤éŒ¯æ¨¡å¼] å°‡é¡¯ç¤ºè©³ç´°CSVè¨˜éŒ„åˆ†æ"
        if parameter == '11':
            debug_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“šåˆ†æ]"
        elif parameter == '12':
            debug_msg += f" [ğŸ†• Type 12 æœˆåº¦P/Eåˆ†æ]"
        elif parameter == '13':
            debug_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸åˆ†æ]"
        elif parameter == '14':
            debug_msg += f" [ğŸ†• Type 14 èè³‡èåˆ¸åˆ†æ]"
        elif parameter == '15':
            debug_msg += f" [ğŸ†• Type 15 èè³‡èåˆ¸åˆ†æ]"
        elif parameter == '16':
            debug_msg += f" [ğŸ†• Type 16 è²¡å‹™æ¯”ç‡åˆ†æ]"
        print(debug_msg)
    
    print(f"è³‡æ–™é¡å‹: {data_desc}")
    if parameter == '11':
        print(f"ğŸ”µ Type 11 ç‰¹è‰²:")
        print(f"   ğŸ“Š å®Œæ•´é€±äº¤æ˜“è³‡æ–™å«OHLCåƒ¹æ ¼æ•¸æ“š")
        print(f"   ğŸ’° äº¤æ˜“é‡èˆ‡æˆäº¤é‡‘é¡åˆ†æ") 
        print(f"   ğŸ›ï¸ ä¸‰å¤§æ³•äººè³‡é‡‘æµå‘ (å¤–è³‡/æŠ•ä¿¡/è‡ªç‡Ÿ)")
        print(f"   ğŸ“ˆ èè³‡èåˆ¸èˆ‡å€Ÿåˆ¸è³£å‡ºæ•¸æ“š")
        print(f"   ğŸ” å¸‚å ´å¾®çµæ§‹åˆ†æ")
    elif parameter == '12':
        print(f"ğŸ†• NEW! Type 12 ç‰¹è‰²:")
        print(f"   ğŸ“Š 20å¹´æœˆåº¦EPSèˆ‡æœ¬ç›Šæ¯”æ•¸æ“š")
        print(f"   ğŸ“ˆ ä¿å®ˆæœ¬ç›Šæ¯”å€æ•¸ (9X-19X) é•·æœŸåˆ†æ")
        print(f"   ğŸ“… æœˆåº¦é »ç‡é©åˆåŸºæœ¬é¢åˆ†æ")
        print(f"   ğŸ” æ”¯æ´å›æ¸¬èˆ‡é•·æœŸæŠ•è³‡ç­–ç•¥")
        print(f"   ğŸ“‹ è£œå……Type 8é€±åº¦åˆ†æ (15X-30Xå€æ•¸)")
        print(f"   ğŸ¯ é•·æœŸä¼°å€¼å»ºæ¨¡èˆ‡çµ„åˆç®¡ç†")
    elif parameter == '13':
        print(f"ğŸ†• NEW! Type 13 ç‰¹è‰²:")
        print(f"   ğŸ“Š æ¯æ—¥èè³‡èåˆ¸é¤˜é¡è©³ç´°è³‡æ–™")
        print(f"   ğŸ“ˆ èè³‡ä½¿ç”¨ç‡èˆ‡ç¶­æŒç‡åˆ†æ")
        print(f"   ğŸ“… æ¯æ—¥é »ç‡é©åˆå¸‚å ´æƒ…ç·’è¿½è¹¤")
        print(f"   ğŸ” 1å¹´æœŸæ¯æ—¥æ­·å²æ•¸æ“š")
        print(f"   ğŸ“‹ è£œå……Type 11é€±åº¦äº¤æ˜“æ•¸æ“š")
    elif parameter == '14':
        print(f"ğŸ†• NEW! Type 14 ç‰¹è‰²:")
        print(f"   ğŸ“Š æ¯å‘¨èè³‡èåˆ¸é¤˜é¡è©³ç´°è³‡æ–™")
        print(f"   ğŸ“ˆ 5å¹´æœŸæ¯å‘¨æ­·å²æ•¸æ“š")
    elif parameter == '15':
        print(f"ğŸ†• NEW! Type 15 ç‰¹è‰²:")
        print(f"   ğŸ“Š æ¯æœˆèè³‡èåˆ¸é¤˜é¡è©³ç´°è³‡æ–™")
        print(f"   ğŸ“ˆ 20å¹´æœŸæ¯æœˆæ­·å²æ•¸æ“š")
    elif parameter == '16':
        print(f"ğŸ†• NEW! Type 16 ç‰¹è‰²:")
        print(f"   ğŸ“Š å–®å­£è²¡å‹™æ¯”ç‡è¡¨è©³ç´°è³‡æ–™ (è¿‘10å­£)")
        print(f"   ğŸ“ˆ ç²åˆ©ã€æˆé•·ã€æ•ˆç‡èˆ‡å„Ÿå‚µèƒ½åŠ›æŒ‡æ¨™")
    
    print(f"åƒæ•¸: {parameter}")
    print(f"ğŸ”§ CSV-ONLYè™•ç†: åƒ…ä½¿ç”¨CSVè¨˜éŒ„åˆ¤æ–·æ–°é®®åº¦")
    print(f"âœ… ç®¡é“ç›¸å®¹: å¿½ç•¥æª”æ¡ˆæ™‚æˆ³ï¼Œé©ç”¨æ–¼CI/CDç’°å¢ƒ")
    print(f"ğŸ“Š æº–ç¢ºè¿½è¹¤: CSVæ˜¯è™•ç†æ­·å²çš„å”¯ä¸€çœŸç›¸ä¾†æº")
    
    print(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 70)
    
    # Enhanced CSV-ONLY smart processing analysis with Type 12 support
    print("CSV-ONLY æ™ºæ…§è™•ç†åˆ†æä¸­ (ä¿®æ­£çš„24å°æ™‚æ–°é®®åº¦æ”¿ç­–)...")
    if parameter == '11':
        print("ğŸ”µ Type 11: åŸ·è¡Œæ©Ÿæ§‹è³‡é‡‘æµå‘æ•¸æ“šåˆ†æ...")
    elif parameter == '12':
        print("ğŸ†• Type 12: åŸ·è¡Œæœˆåº¦æœ¬ç›Šæ¯”é•·æœŸæ•¸æ“šåˆ†æ...")
    elif parameter == '13':
        print("ğŸ†• Type 13: åŸ·è¡Œæ¯æ—¥èè³‡èåˆ¸æ•¸æ“šåˆ†æ...")
    elif parameter == '14':
        print("ğŸ†• Type 14: åŸ·è¡Œæ¯å‘¨èè³‡èåˆ¸æ•¸æ“šåˆ†æ...")
    elif parameter == '15':
        print("ğŸ†• Type 15: åŸ·è¡Œæ¯æœˆèè³‡èåˆ¸æ•¸æ“šåˆ†æ...")
    elif parameter == '16':
        print("ğŸ†• Type 16: åŸ·è¡Œå–®å­£è²¡å‹™æ¯”ç‡è¡¨æ•¸æ“šåˆ†æ...")
    
    stocks_to_process, processing_strategy = determine_stocks_to_process_csv_only(
        parameter, stock_ids, stock_mapping, debug_mode
    )
    
    if not stocks_to_process:
        finish_msg = "æ‰€æœ‰è³‡æ–™éƒ½æ˜¯æ–°é®®çš„ (CSVé¡¯ç¤º24å°æ™‚å…§)ï¼Œç„¡éœ€è™•ç†!"
        if parameter == '11':
            finish_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“šå·²æ˜¯æœ€æ–°]"
        elif parameter == '12':
            finish_msg += f" [ğŸ†• Type 12 æœˆåº¦P/Eå·²æ˜¯æœ€æ–°]"
        elif parameter == '13':
            finish_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸å·²æ˜¯æœ€æ–°]"
        elif parameter == '14':
            finish_msg += f" [ğŸ†• Type 14 æ¯å‘¨èè³‡èåˆ¸å·²æ˜¯æœ€æ–°]"
        elif parameter == '15':
            finish_msg += f" [ğŸ†• Type 15 æ¯æœˆèè³‡èåˆ¸å·²æ˜¯æœ€æ–°]"
        elif parameter == '16':
            finish_msg += f" [ğŸ†• Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨å·²æ˜¯æœ€æ–°]"
        print(finish_msg)
        save_csv_results_csv_only(parameter, stock_ids, {}, {}, stock_mapping, {})
        print("ä»»å‹™å®Œæˆ!")
        return
    
    # Update processing list for test mode
    original_count = len(stock_ids)
    if test_mode and processing_strategy != "UP_TO_DATE":
        stocks_to_process = stocks_to_process[:3]
        test_limit_msg = f"[æ¸¬è©¦æ¨¡å¼] é™åˆ¶è™•ç† {len(stocks_to_process)} æ”¯è‚¡ç¥¨"
        if parameter == '11':
            test_limit_msg += f" [ğŸ”µ Type 11 æ¸¬è©¦]"
        elif parameter == '12':
            test_limit_msg += f" [ğŸ†• Type 12 æ¸¬è©¦]"
        elif parameter == '13':
            test_limit_msg += f" [ğŸ†• Type 13 æ¸¬è©¦]"
        elif parameter == '14':
            test_limit_msg += f" [ğŸ†• Type 14 æ¸¬è©¦]"
        elif parameter == '15':
            test_limit_msg += f" [ğŸ†• Type 15 æ¸¬è©¦]"
        elif parameter == '16':
            test_limit_msg += f" [ğŸ†• Type 16 æ¸¬è©¦]"
        print(test_limit_msg)
    
    processing_count = len(stocks_to_process)
    print(f"è™•ç†ç­–ç•¥: {processing_strategy}")
    print(f"è™•ç†ç¯„åœ: {processing_count}/{original_count} æ”¯è‚¡ç¥¨")
    print(f"ğŸ”§ CSV-ONLY: æ¯æ”¯è‚¡ç¥¨æœ€å¤š 4 æ¬¡å˜—è©¦æ©Ÿæœƒ (1+3)")
    if parameter == '11':
        print(f"ğŸ”µ Type 11: æ©Ÿæ§‹æ•¸æ“šè¤‡é›œåº¦ - å»¶é•·è¶…æ™‚èˆ‡é‡è©¦é–“éš”")
    elif parameter == '12':
        print(f"ğŸ†• Type 12: æœˆåº¦P/Eè¤‡é›œåº¦ - 20å¹´æ•¸æ“šè™•ç†å„ªåŒ–")
    elif parameter == '13':
        print(f"ğŸ†• Type 13: æ¯æ—¥æ•¸æ“šè¤‡é›œåº¦ - æ¯æ—¥èè³‡èåˆ¸è™•ç†å„ªåŒ–")
    elif parameter in ['14', '15']:
        print(f"ğŸ†• Type {parameter}: èè³‡èåˆ¸æ•¸æ“šè¤‡é›œåº¦ - è™•ç†å„ªåŒ–")
    elif parameter == '16':
        print(f"ğŸ†• Type 16: å–®å­£è²¡å‹™æ¯”ç‡è¡¨æ•¸æ“šè¤‡é›œåº¦ - è™•ç†å„ªåŒ–")
    print(f"âœ… è¨˜éŒ„å°å‘: æˆåŠŸå¾Œæ›´æ–°CSVæ™‚æˆ³ç‚ºç•¶å‰æ™‚é–“")
    print("-" * 70)
    
    # Enhanced batch processing with CSV-ONLY approach and Types 11/12 support
    success_count = 0
    failed_count = 0
    results_data = {}
    process_times = {}
    last_update_times = {}  # NEW: Track actual completion time per stock
    retry_stats = {}
    
    # Initialize CSV with enhanced CSV-ONLY logic
    init_msg = f"åˆå§‹åŒ– CSV-ONLY CSV æª”æ¡ˆ..."
    if parameter == '11':
        init_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“šçµæ§‹]"
    elif parameter == '12':
        init_msg += f" [ğŸ†• Type 12 æœˆåº¦P/Eçµæ§‹]"
    elif parameter == '13':
        init_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸çµæ§‹]"
    elif parameter == '14':
        init_msg += f" [ğŸ†• Type 14 æ¯å‘¨èè³‡èåˆ¸çµæ§‹]"
    elif parameter == '15':
        init_msg += f" [ğŸ†• Type 15 æ¯æœˆèè³‡èåˆ¸çµæ§‹]"
    elif parameter == '16':
        init_msg += f" [ğŸ†• Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨çµæ§‹]"
    print(init_msg)
    save_csv_results_csv_only(parameter, stock_ids, {}, {}, stock_mapping, {})
    
    # Enhanced processing with Types 11/12 considerations
    total_attempts = 0
    for i, stock_id in enumerate(stocks_to_process, 1):
        # Skip TAIEX (0000) for unsupported data types
        if stock_id == '0000' and str(parameter) in ['1', '4', '5', '6', '7', '9', '10', '12', '15', '16']:
            print(f"\n[{i}/{len(stocks_to_process)}] âš ï¸ è·³é TAIEX (0000): Data Type {parameter} ä¸æ”¯æ´æ­¤æŒ‡æ•¸")
            # Record as handled (success=True) to prevent retries and ensure correct CSV entry
            results_data[stock_id] = True
            process_times[stock_id] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            retry_stats[stock_id] = {'attempts': 1, 'error': 'Skipped (Unsupported Index)', 'duration': 0}
            continue

        process_msg = f"\n[{i}/{len(stocks_to_process)}] è™•ç†è‚¡ç¥¨: {stock_id}"
        if parameter == '11':
            process_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“š]"
        elif parameter == '12':
            process_msg += f" [ğŸ†• Type 12 æœˆåº¦P/E]"
        elif parameter == '13':
            process_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸]"
        elif parameter == '14':
            process_msg += f" [ğŸ†• Type 14 æ¯å‘¨èè³‡èåˆ¸]"
        elif parameter == '15':
            process_msg += f" [ğŸ†• Type 15 æ¯æœˆèè³‡èåˆ¸]"
        elif parameter == '16':
            process_msg += f" [ğŸ†• Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨]"
        print(process_msg)
        
        # Record start time
        current_process_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        process_times[stock_id] = current_process_time
        
        # Execute with enhanced retry mechanism including Types 11/12 support
        success, attempts, error_msg, duration = run_get_good_info_with_retry(
            stock_id, parameter, debug_mode, max_retries=3
        )

        # NEW: Record actual completion time (when download finished)
        download_complete_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        last_update_times[stock_id] = download_complete_time

        # Record results
        results_data[stock_id] = success
        retry_stats[stock_id] = {
            'attempts': attempts,
            'error': error_msg,
            'duration': duration
        }
        total_attempts += attempts
        
        # Update global variables for signal handler
        current_results_data = results_data.copy()
        current_process_times = process_times.copy()
        current_last_update_times = last_update_times.copy()  # NEW: Track completion times
        current_retry_stats = retry_stats.copy()
        
        if success:
            success_count += 1
            success_msg = f"   ğŸ¯ "
            if attempts > 1:
                success_msg += f"é‡è©¦æˆåŠŸ: ç¬¬ {attempts} æ¬¡å˜—è©¦æˆåŠŸ"
            else:
                success_msg += f"é¦–æ¬¡æˆåŠŸ"
            if parameter == '11':
                success_msg += f" [Type 11 æ©Ÿæ§‹æ•¸æ“šå®Œæˆ]"
            elif parameter == '12':
                success_msg += f" [Type 12 æœˆåº¦P/Eå®Œæˆ]"
            elif parameter == '13':
                success_msg += f" [Type 13 èè³‡èåˆ¸å®Œæˆ]"
            elif parameter == '14':
                success_msg += f" [Type 14 æ¯å‘¨èè³‡èåˆ¸å®Œæˆ]"
            elif parameter == '15':
                success_msg += f" [Type 15 æ¯æœˆèè³‡èåˆ¸å®Œæˆ]"
            elif parameter == '16':
                success_msg += f" [Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨å®Œæˆ]"
            print(success_msg)
        else:
            failed_count += 1
            failure_msg = f"   ğŸ’¥ æœ€çµ‚å¤±æ•—: {attempts} æ¬¡å˜—è©¦å¾Œå¤±æ•— (æœ€å¤š4æ¬¡)"
            if parameter == '11':
                failure_msg += f" [Type 11 æ©Ÿæ§‹æ•¸æ“šå¤±æ•—]"
            elif parameter == '12':
                failure_msg += f" [Type 12 æœˆåº¦P/Eå¤±æ•—]"
            elif parameter == '13':
                failure_msg += f" [Type 13 èè³‡èåˆ¸å¤±æ•—]"
            elif parameter == '14':
                failure_msg += f" [Type 14 æ¯å‘¨èè³‡èåˆ¸å¤±æ•—]"
            elif parameter == '15':
                failure_msg += f" [Type 15 æ¯æœˆèè³‡èåˆ¸å¤±æ•—]"
            elif parameter == '16':
                failure_msg += f" [Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨å¤±æ•—]"
            print(failure_msg)
        
        # Save progress after each stock with enhanced CSV-ONLY logic
        try:
            save_csv_results_csv_only(parameter, stock_ids, results_data, process_times, stock_mapping, retry_stats, last_update_times)
            progress_msg = f"   ğŸ“ CSV-ONLY CSV å·²æ›´æ–° ({i}/{len(stocks_to_process)} å®Œæˆ)"
            if parameter == '11':
                progress_msg += f" [Type 11]"
            elif parameter == '12':
                progress_msg += f" [Type 12]"
            elif parameter == '13':
                progress_msg += f" [Type 13]"
            elif parameter == '14':
                progress_msg += f" [Type 14]"
            elif parameter == '15':
                progress_msg += f" [Type 15]"
            elif parameter == '16':
                progress_msg += f" [Type 16]"
            print(progress_msg)
        except Exception as e:
            print(f"   âš ï¸ CSV æ›´æ–°å¤±æ•—: {e}")
        
        # Enhanced delay between stocks with Types 11-16 considerations
        if i < len(stocks_to_process):
            if parameter in ['11', '12', '13', '14', '15', '16']:
                delay = 5 if success else 8  # Extended for complex data types
            else:
                delay = 3 if success else 5
            time.sleep(delay)
    
    # Final CSV save with enhanced CSV-ONLY logic
    print("\n" + "=" * 70)
    final_save_msg = "æœ€çµ‚ CSV-ONLY CSV çµæœ..."
    if parameter == '11':
        final_save_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“šå®Œæ•´è¨˜éŒ„]"
    elif parameter == '12':
        final_save_msg += f" [ğŸ†• Type 12 æœˆåº¦P/Eå®Œæ•´è¨˜éŒ„]"
    elif parameter == '13':
        final_save_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸å®Œæ•´è¨˜éŒ„]"
    elif parameter == '14':
        final_save_msg += f" [ğŸ†• Type 14 æ¯å‘¨èè³‡èåˆ¸å®Œæ•´è¨˜éŒ„]"
    elif parameter == '15':
        final_save_msg += f" [ğŸ†• Type 15 æ¯æœˆèè³‡èåˆ¸å®Œæ•´è¨˜éŒ„]"
    elif parameter == '16':
        final_save_msg += f" [ğŸ†• Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨å®Œæ•´è¨˜éŒ„]"
    print(final_save_msg)
    save_csv_results_csv_only(parameter, stock_ids, results_data, process_times, stock_mapping, retry_stats, last_update_times)
    
    # Enhanced Summary with CSV-ONLY approach and Types 11/12 support
    print("\n" + "=" * 70)
    print("Enhanced Execution Summary (v3.1.0) - Pipeline Compatible")
    print("Complete 16 Data Types + CSV-ONLY Freshness + Enhanced Processing")
    if parameter == '11':
        print("ğŸ”µ Type 11 Weekly Trading Data with Institutional Flows")
    elif parameter == '12':
        print("ğŸ†• NEW! Type 12 EPS x PER Monthly for Long-Term Analysis")
    elif parameter == '13':
        print("ğŸ†• NEW! Type 13 Daily Margin Balance for Market Sentiment")
    elif parameter == '14':
        print("ğŸ†• NEW! Type 14 Weekly Margin Balance")
    elif parameter == '15':
        print("ğŸ†• NEW! Type 15 Monthly Margin Balance")
    elif parameter == '16':
        print("ğŸ†• NEW! Type 16 Quarterly Financial Ratio Analysis")
    print("=" * 70)
    print(f"è³‡æ–™é¡å‹: {data_desc}")
    print(f"è™•ç†ç­–ç•¥: {processing_strategy}")
    print(f"ç¸½è‚¡ç¥¨æ•¸: {original_count} æ”¯")
    print(f"éœ€è™•ç†è‚¡ç¥¨æ•¸: {processing_count} æ”¯") 
    print(f"å¯¦éš›è™•ç†: {len(stocks_to_process)} æ”¯è‚¡ç¥¨")
    print(f"æœ€çµ‚æˆåŠŸ: {success_count} æ”¯")
    print(f"æœ€çµ‚å¤±æ•—: {failed_count} æ”¯")
    print(f"ç¸½å˜—è©¦æ¬¡æ•¸: {total_attempts} æ¬¡")
    print(f"å¹³å‡å˜—è©¦æ¬¡æ•¸: {total_attempts/len(stocks_to_process):.1f} æ¬¡/è‚¡ç¥¨")
    
    if processing_count > 0:
        final_success_rate = (success_count / processing_count * 100)
        success_rate_msg = f"ğŸ¯ CSV-ONLY æœ€çµ‚æˆåŠŸç‡: {final_success_rate:.1f}%"
        if parameter == '11':
            success_rate_msg += f" (Type 11 æ©Ÿæ§‹æ•¸æ“šè™•ç†)"
        elif parameter == '12':
            success_rate_msg += f" (Type 12 æœˆåº¦P/Eè™•ç†)"
        elif parameter == '13':
            success_rate_msg += f" (Type 13 èè³‡èåˆ¸è™•ç†)"
        elif parameter == '14':
            success_rate_msg += f" (Type 14 æ¯å‘¨èè³‡èåˆ¸è™•ç†)"
        elif parameter == '15':
            success_rate_msg += f" (Type 15 æ¯æœˆèè³‡èåˆ¸è™•ç†)"
        elif parameter == '16':
            success_rate_msg += f" (Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨è™•ç†)"
        else:
            success_rate_msg += f" (æ¨™æº–è™•ç†)"
        print(success_rate_msg)
    
    # Show enhanced CSV-ONLY improvements with Types 11/12 features
    print(f"\nâœ… CSV-ONLY æ”¹å–„é …ç›®:")
    print(f"   â€¢ åƒ…ä½¿ç”¨CSV: å®Œå…¨å¿½ç•¥æª”æ¡ˆæ™‚æˆ³ï¼Œä½¿ç”¨CSVè¨˜éŒ„")
    print(f"   â€¢ ç®¡é“ç›¸å®¹: é©ç”¨æ–¼CI/CDç’°å¢ƒï¼Œæª”æ¡ˆç¸½æ˜¯æ–°çš„")
    print(f"   â€¢ æº–ç¢ºè¿½è¹¤: CSVæ˜¯è™•ç†æ­·å²çš„å”¯ä¸€çœŸç›¸ä¾†æº")
    print(f"   â€¢ æˆåŠŸæ›´æ–°: æˆåŠŸè™•ç†å¾Œç«‹å³æ›´æ–°CSVæ™‚æˆ³")
    if parameter == '11':
        print(f"   ğŸ”µ Type 11 å¢å¼·:")
        print(f"     - æ©Ÿæ§‹è³‡é‡‘æµå‘æ•¸æ“šæ”¯æ´")
        print(f"     - å»¶é•·è¶…æ™‚æ™‚é–“é©æ‡‰è¤‡é›œåº¦")
        print(f"     - å°ˆç”¨é‡è©¦é–“éš”é…ç½®")
        print(f"     - å®Œæ•´é€±äº¤æ˜“æ•¸æ“šè¨˜éŒ„")
    elif parameter == '12':
        print(f"   ğŸ†• Type 12 å¢å¼·:")
        print(f"     - æœˆåº¦æœ¬ç›Šæ¯”é•·æœŸæ•¸æ“šæ”¯æ´")
        print(f"     - 20å¹´æ­·å²æ•¸æ“šè™•ç†å„ªåŒ–")
        print(f"     - ä¿å®ˆå€æ•¸åˆ†æ (9X-19X)")
        print(f"     - é•·æœŸä¼°å€¼æ¨¡å‹æ”¯æ´")
        print(f"     - è£œå……é€±åº¦åˆ†æ (Type 8)")
    elif parameter == '13':
        print(f"   ğŸ†• Type 13 å¢å¼·:")
        print(f"     - æ¯æ—¥èè³‡èåˆ¸é¤˜é¡æ•¸æ“šæ”¯æ´")
        print(f"     - 1å¹´æœŸæ¯æ—¥æ­·å²æ•¸æ“š")
        print(f"     - å¸‚å ´æƒ…ç·’æŒ‡æ¨™è¿½è¹¤")
        print(f"     - è£œå……Type 11é€±åº¦æ•¸æ“š")
    elif parameter in ['14', '15']:
        print(f"   ğŸ†• Type {parameter} å¢å¼·:")
        print(f"     - èè³‡èåˆ¸é¤˜é¡æ•¸æ“šæ”¯æ´")
        print(f"     - æ­·å²æ•¸æ“šè¶¨å‹¢åˆ†æ")
    elif parameter == '16':
        print(f"   ğŸ†• Type 16 å¢å¼·:")
        print(f"     - å–®å­£è²¡å‹™æ¯”ç‡è¡¨æ•¸æ“šæ”¯æ´")
        print(f"     - è¿‘10å­£è²¡å‹™æ¯”ç‡è¶¨å‹¢è¿½è¹¤")
    
    print(f"\nçµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if failed_count > 0:
        print(f"\nâš ï¸ ä»æœ‰ {failed_count} æ”¯è‚¡ç¥¨ç¶“4æ¬¡å˜—è©¦å¾Œå¤±æ•—")
        print("å»ºè­°:")
        print("   â€¢ æª¢æŸ¥ç¶²è·¯é€£ç·šç‹€æ…‹")
        print("   â€¢ ä½¿ç”¨ --debug æŸ¥çœ‹è©³ç´°éŒ¯èª¤")
        print("   â€¢ å–®ç¨åŸ·è¡Œå¤±æ•—è‚¡ç¥¨: python GetGoodInfo.py [è‚¡ç¥¨ä»£è™Ÿ] [é¡å‹]")
        print("   â€¢ CSV-ONLY: ç¾åœ¨èƒ½æº–ç¢ºè¿½è¹¤åŸºæ–¼è¨˜éŒ„çš„è™•ç†æ­·å²")
        if parameter == '11':
            print("   ğŸ”µ Type 11 ç‰¹åˆ¥å»ºè­°:")
            print("     - æ©Ÿæ§‹æ•¸æ“šè¤‡é›œï¼Œå¯èƒ½éœ€è¦å¤šæ¬¡é‡è©¦")
            print("     - æª¢æŸ¥ç¶²è·¯ç©©å®šæ€§ä»¥è™•ç†å¤§é‡æ•¸æ“š")
            print("     - è€ƒæ…®åœ¨ç¶²è·¯è¼ƒä½³æ™‚æ®µé‡æ–°åŸ·è¡Œ")
        elif parameter == '12':
            print("   ğŸ†• Type 12 ç‰¹åˆ¥å»ºè­°:")
            print("     - 20å¹´æœˆåº¦æ•¸æ“šé‡å¤§ï¼Œéœ€è¦ç©©å®šé€£ç·š")
            print("     - æª¢æŸ¥ç£ç¢Ÿç©ºé–“ä»¥å­˜å„²å¤§é‡æ­·å²è³‡æ–™")
            print("     - è€ƒæ…®åˆ†æ‰¹è™•ç†ä»¥é™ä½å–®æ¬¡è² è¼‰")
            print("     - èˆ‡Type 8æ­é…ä½¿ç”¨ç²å¾—å®Œæ•´P/Eåˆ†æ")
        elif parameter == '13':
            print("   ğŸ†• Type 13 ç‰¹åˆ¥å»ºè­°:")
            print("     - æ¯æ—¥æ•¸æ“šæ›´æ–°é »ç¹ï¼Œç¢ºä¿ä½¿ç”¨æœ€æ–°æ•¸æ“š")
            print("     - æª¢æŸ¥ 'æŸ¥1å¹´' æŒ‰éˆ•æ˜¯å¦å¯ç”¨")
            print("     - é©åˆåœ¨æ”¶ç›¤å¾ŒåŸ·è¡Œ (Evening)")
        elif parameter in ['14', '15']:
            print(f"   ğŸ†• Type {parameter} ç‰¹åˆ¥å»ºè­°:")
            print("     - æª¢æŸ¥ç›¸é—œæŒ‰éˆ• ('æŸ¥5å¹´'/'æŸ¥20å¹´') æ˜¯å¦å¯ç”¨")
        elif parameter == '16':
            print("   ğŸ†• Type 16 ç‰¹åˆ¥å»ºè­°:")
            print("     - ç­‰å¾… 5 ç§’è®“å­£åº¦è³‡æ–™è¼‰å…¥å¾Œå†ä¸‹è¼‰")
    else:
        complete_msg = f"\nğŸ‰ å®Œç¾åŸ·è¡Œ! æ‰€æœ‰ {success_count} æ”¯è‚¡ç¥¨å‡è™•ç†æˆåŠŸ"
        if parameter == '11':
            complete_msg += f" [ğŸ”µ Type 11 æ©Ÿæ§‹æ•¸æ“šå®Œæ•´]"
        elif parameter == '12':
            complete_msg += f" [ğŸ†• Type 12 æœˆåº¦P/Eå®Œæ•´]"
        elif parameter == '13':
            complete_msg += f" [ğŸ†• Type 13 èè³‡èåˆ¸å®Œæ•´]"
        elif parameter == '14':
            complete_msg += f" [ğŸ†• Type 14 æ¯å‘¨èè³‡èåˆ¸å®Œæ•´]"
        elif parameter == '15':
            complete_msg += f" [ğŸ†• Type 15 æ¯æœˆèè³‡èåˆ¸å®Œæ•´]"
        elif parameter == '16':
            complete_msg += f" [ğŸ†• Type 16 å–®å­£è²¡å‹™æ¯”ç‡è¡¨å®Œæ•´]"
        print(complete_msg)
        
        if total_attempts > len(stocks_to_process):
            improvement = total_attempts - len(stocks_to_process)
            improvement_msg = f"ğŸ’ª é‡è©¦æ©Ÿåˆ¶é¡å¤–æŒ½æ•‘äº† {improvement} æ¬¡å¤±æ•—"
            if parameter == '11':
                improvement_msg += f" [Type 11 æ©Ÿæ§‹æ•¸æ“šéŸŒæ€§]"
            elif parameter == '12':
                improvement_msg += f" [Type 12 æœˆåº¦æ•¸æ“šéŸŒæ€§]"
            elif parameter == '13':
                improvement_msg += f" [Type 13 æ¯æ—¥æ•¸æ“šéŸŒæ€§]"
            elif parameter in ['14', '15']:
                improvement_msg += f" [Type {parameter} æ•¸æ“šéŸŒæ€§]"
            elif parameter == '16':
                improvement_msg += f" [Type 16 å–®å­£æ•¸æ“šéŸŒæ€§]"
            print(improvement_msg)
        
        final_achievement = f"âœ… CSV-ONLYç‰ˆæœ¬æä¾›æº–ç¢ºçš„è¨˜éŒ„å°å‘è™•ç†è¿½è¹¤"
        if parameter == '11':
            final_achievement += f"\nğŸš€ Type 11 æ©Ÿæ§‹è³‡é‡‘æµå‘æ•¸æ“šä¸‹è¼‰å®Œæˆ - åŒ…å«å¤–è³‡ã€æŠ•ä¿¡ã€è‡ªç‡Ÿå®Œæ•´äº¤æ˜“è³‡è¨Š!"
        elif parameter == '12':
            final_achievement += f"\nğŸš€ Type 12 æœˆåº¦æœ¬ç›Šæ¯”æ•¸æ“šä¸‹è¼‰å®Œæˆ - åŒ…å«20å¹´æœˆåº¦P/Eåˆ†ææ”¯æ´é•·æœŸæŠ•è³‡ç­–ç•¥!"
        elif parameter == '13':
            final_achievement += f"\nğŸš€ Type 13 æ¯æ—¥èè³‡èåˆ¸é¤˜é¡ä¸‹è¼‰å®Œæˆ - åŒ…å«æ¯æ—¥å¸‚å ´æƒ…ç·’æŒ‡æ¨™!"
        elif parameter == '14':
            final_achievement += f"\nğŸš€ Type 14 æ¯å‘¨èè³‡èåˆ¸é¤˜é¡ä¸‹è¼‰å®Œæˆ!"
        elif parameter == '15':
            final_achievement += f"\nğŸš€ Type 15 æ¯æœˆèè³‡èåˆ¸é¤˜é¡ä¸‹è¼‰å®Œæˆ!"
        print(final_achievement)

if __name__ == "__main__":
    main()
